# Kafka Hands-on Training - Wavestone Cloud Forward ğŸš€

## ğŸ† Goal of the Training

Ce hands-on a pour but de dÃ©ployer un cluster Kafka complet sur GCP via Terraform, avec producteurs, topics, messages et groupes de consommateurs. Ce TP vous permettra de comprendre le fonctionnement interne de Kafka et les avantages des architectures event-driven.

---

## ğŸ“€ Introduction : Event-Driven Architecture (EDA)

### âš–ï¸ Principe

Une architecture orientÃ©e Ã©vÃ©nements repose sur la production, la dÃ©tection et la rÃ©action Ã  des Ã©vÃ©nements. Les services communiquent en Ã©changeant des messages plutÃ´t qu'en faisant des requÃªtes directes.

### âœ¨ Avantages

* DÃ©couplage fort entre les services
* Haute scalabilitÃ©
* Temps rÃ©el
* ExtensibilitÃ© facilitÃ©e

### ğŸ›ï¸ Use cases

* Traitement de logs
* Monitoring en temps rÃ©el
* Applications bancaires (transactions)
* IntÃ©gration de microservices

### ğŸŒ Comparaison avec API REST

| Aspect      | API REST          | Event-driven           |
| ----------- | ----------------- | ---------------------- |
| Couplage    | Fort              | Faible                 |
| Mode        | Pull              | Push                   |
| RÃ©activitÃ©  | SÃ©quentiel        | Asynchrone             |
| ScalabilitÃ© | Limitee par appel | Forte grÃ¢ce Ã  la queue |

---

## ğŸ“… Kafka : principes fondamentaux

![Kafka principles] (images/Kafka schema.gif)

Apache Kafka est une plateforme de streaming d'Ã©vÃ©nements distribuÃ©e. Elle repose sur un modÃ¨le **pub/sub** avec les Ã©lÃ©ments suivants :

* **Producteurs** : envoient des messages vers un **topic**
* **Topics** : unitÃ© logique qui regroupe les messages
* **Brokers** : serveurs qui stockent et distribuent les messages
* **Consumers** : abonnÃ©s qui consomment les messages
* **Consumer Groups** : ensemble de consumers qui partagent la consommation d'un topic

### âœ¨ Avantages

* TolÃ©rance aux pannes (grÃ¢ce Ã  la rÃ©plication)
* ScalabilitÃ© horizontale
* Performances Ã©levÃ©es
* Persistance des messages

### ğŸ›ï¸ Use cases

![Top 5 Kafka Uses Cases] (images/Top 5 Kafka uses.webp)

* Monitoring d'applications
* Streaming de donnÃ©es IoT
* IntÃ©gration entre microservices
* ETL en temps rÃ©el

---

## ğŸ“š Objectif du TP

Le TP consiste Ã  :

* DÃ©ployer une instance GCP automatiquement avec **Terraform**
* Configurer cette instance pour exÃ©cuter un cluster Kafka via **Docker Compose**
* Simuler un flux de messages entre producteurs et consommateurs
* Visualiser l'Ã©tat du cluster via un monitoring **Prometheus + Grafana**
* Simuler une panne et vÃ©rifier la rÃ©silience de Kafka

### ğŸ“˜ SchÃ©ma dâ€™architecture

![TP Kafka deployment architecture] (images/kafka-cluster-running.png)

## ğŸ› ï¸ DÃ©roulement du TP

### ğŸ” 1. Lancement du pipeline GitHub Actions

Le pipeline est dÃ©clenchÃ© via GitHub Actions (workflow\_dispatch).

#### ğŸ”¹ Ã‰tapes :

* **Terraform Apply** : dÃ©ploie une instance GCP Debian
* **Configuration VM** : mise Ã  jour, installation de git et git clone du projet
* **Provisioning** : installation de Java, Docker, Docker Compose
* **ExÃ©cution** :

  * Lancement du cluster Kafka (3 brokers)
  * HAProxy pour distribuer les requÃªtes
  * Prometheus + Grafana pour le monitoring

### ğŸ”¦ 2. Envoi et consommation de messages

* 3 producteurs envoient des messages
* 3 topics sont crÃ©Ã©s
* 3 consumer groups consomment :

  * Group 1: 1 consumer
  * Group 2: 2 consumers
  * Group 3: 3 consumers

### â„ï¸ 3. Simulation de panne

* Un broker Kafka est stoppÃ© manuellement
* Le monitoring Grafana indique l'Ã©tat du cluster (2/3 brokers actifs)
* La consommation des messages continue sans erreur : preuve de rÃ©silience

---

## ğŸ­ Illustrations (ajouter les images/gif)

### âœ… Kafka running on GCP

![Kafka Cluster Running](images/kafka-cluster-running.png)

### âœ… Grafana Dashboard

![Grafana Monitoring](images/grafana-dashboard.png)

### âŒ Simulated Broker Failure

![Kafka Broker Down](images/broker-down.gif)

### âœ… Message Flow

![Message Flow](images/message-flow.gif)

---

## ğŸ‰ Conclusion

Vous avez :

* DÃ©ployÃ© un cluster Kafka automatiquement avec Terraform
* Mis en place une architecture event-driven
* ObservÃ© le comportement en cas de panne
* MonitorÃ© l'activitÃ© grÃ¢ce Ã  Prometheus + Grafana

### âœ¨ Prolongements possibles :

* Ajouter Kafka Connect pour intÃ©gration de base de donnÃ©es
* Utiliser Kafka Streams pour le traitement temps rÃ©el
* DÃ©ployer sur Kubernetes
* IntÃ©grer avec un SI existant

---

Merci pour votre participation Ã  cette formation Kafka âœ¨
